# -*- coding: utf-8 -*-
"""
Breast Cancer Classification using XGBoost
Based on the paper:
"Breast Cancer Classification using XGBoost" by Rahmanul Hoque et al.
World Journal of Advanced Research and Reviews, 2024
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
def load_data():
    """
    Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø³Ø±Ø·Ø§Ù† Ù¾Ø³ØªØ§Ù† ÙˆÛŒØ³Ú©Ø§Ù†Ø³ÛŒÙ†
    """
    try:
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² UCI repository
        from ucimlrepo import fetch_ucirepo
        breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§
        X = breast_cancer_wisconsin_diagnostic.data.features
        y = breast_cancer_wisconsin_diagnostic.data.targets
        
        print("âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯")
        print(f"ğŸ“Š Ø´Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {X.shape}")
        print(f"ğŸ¯ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§: {y.nunique()[0]}")
        
        return X, y
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
        print("ğŸ“¥ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ Ù…Ø­Ù„ÛŒ...")
        
        # Ù…Ø³ÛŒØ± Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ CSV Ø®ÙˆØ¯ Ø±Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯
        try:
            data = pd.read_csv('../Docs/data.csv')
            X = data.drop(['id', 'diagnosis', 'Unnamed: 32'], axis=1, errors='ignore')
            y = data['diagnosis']
            return X, y
        except:
            print("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯Ù†Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
            return None, None

# 2. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
def preprocess_data(X, y):
    """
    Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    """
    # Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ (M=1, B=0)
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø¢Ø²Ù…ÙˆÙ† (80% - 20%)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    print("\nğŸ“ˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:")
    print(f"   Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ: {X_train.shape[0]} Ù†Ù…ÙˆÙ†Ù‡")
    print(f"   Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†: {X_test.shape[0]} Ù†Ù…ÙˆÙ†Ù‡")
    print(f"   Ø¯Ø±ØµØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†: {(X_test.shape[0]/(X_train.shape[0]+X_test.shape[0]))*100:.1f}%")
    
    return X_train, X_test, y_train, y_test

# 3. ØªØ¬Ø³Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
def visualize_data(X, y):
    """
    ØªØ¬Ø³Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    """
    # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame Ø¨Ø±Ø§ÛŒ ØªØ¬Ø³Ù… Ø¨Ù‡ØªØ±
    df = X.copy()
    df['diagnosis'] = y
    
    # ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ¬Ø³Ù…
    n_features = min(10, X.shape[1])
    features_to_plot = X.columns[:n_features]
    
    # Ù†Ù…ÙˆØ¯Ø§Ø± Ø¬Ø¹Ø¨Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    for idx, feature in enumerate(features_to_plot):
        if idx < len(axes):
            sns.boxplot(x='diagnosis', y=feature, data=df, ax=axes[idx])
            axes[idx].set_title(f'Boxplot of {feature}')
            axes[idx].set_xlabel('')
            axes[idx].set_xticklabels(['Benign', 'Malignant'])
    
    plt.suptitle('Boxplots of Selected Features by Diagnosis', fontsize=16, y=1.02)
    plt.tight_layout()
    plt.show()
    
    # Ù†Ù‚Ø´Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
    plt.figure(figsize=(12, 10))
    correlation_matrix = X.corr()
    sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, 
                square=True, linewidths=0.5, cbar_kws={"shrink": 0.8})
    plt.title('Feature Correlation Heatmap', fontsize=16)
    plt.tight_layout()
    plt.show()
    
    # ØªÙˆØ²ÛŒØ¹ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
    important_features = ['radius_mean', 'texture_mean', 'perimeter_mean', 
                         'area_mean', 'concavity_mean']
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    for idx, feature in enumerate(important_features):
        if idx < len(axes) and feature in X.columns:
            sns.histplot(data=df, x=feature, hue='diagnosis', kde=True, 
                        ax=axes[idx], element='step', stat='density')
            axes[idx].set_title(f'Distribution of {feature}')
            axes[idx].legend(['Benign', 'Malignant'])
    
    plt.suptitle('Distribution of Important Features', fontsize=16, y=1.02)
    plt.tight_layout()
    plt.show()

# 4. Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ XGBoost
def train_xgboost(X_train, X_test, y_train, y_test):
    """
    Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ XGBoost
    """
    print("\nğŸš€ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ XGBoost...")
    
    # ØªØ¹Ø±ÛŒÙ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„ (Ù…Ø·Ø§Ø¨Ù‚ Ù…Ù‚Ø§Ù„Ù‡)
    params = {
        'objective': 'binary:logistic',
        'learning_rate': 0.3,
        'max_depth': 4,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42,
        'eval_metric': 'logloss',
        'n_estimators': 100
    }
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    model = xgb.XGBClassifier(**params)
    model.fit(X_train, y_train)
    
    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    return model, y_pred, y_pred_proba

# 5. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
def evaluate_model(y_test, y_pred, y_pred_proba):
    """
    Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„
    """
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    # Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ
    cm = confusion_matrix(y_test, y_pred)
    
    print("\nğŸ“Š Ù†ØªØ§ÛŒØ¬ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„:")
    print("=" * 40)
    print(f"âœ… Ø¯Ù‚Øª (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"ğŸ¯ ØµØ­Øª (Precision): {precision:.4f} ({precision*100:.2f}%)")
    print(f"ğŸ” Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ (Recall): {recall:.4f} ({recall*100:.2f}%)")
    print(f"âš–ï¸  Ø§Ù…ØªÛŒØ§Ø² F1: {f1:.4f} ({f1*100:.2f}%)")
    
    # Ù†Ù…Ø§ÛŒØ´ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Benign', 'Malignant'],
                yticklabels=['Benign', 'Malignant'])
    plt.title('Confusion Matrix', fontsize=16)
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'confusion_matrix': cm
    }

# 6. ØªØ¬Ø³Ù… Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
def plot_feature_importance(model, feature_names):
    """
    ØªØ¬Ø³Ù… Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    """
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    importance = model.feature_importances_
    feature_importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importance
    }).sort_values('Importance', ascending=False)
    
    # Ù†Ù…Ø§ÛŒØ´ 15 ÙˆÛŒÚ˜Ú¯ÛŒ Ù…Ù‡Ù…
    top_features = feature_importance_df.head(15)
    
    plt.figure(figsize=(12, 8))
    bars = plt.barh(range(len(top_features)), top_features['Importance'], align='center')
    plt.yticks(range(len(top_features)), top_features['Feature'])
    plt.xlabel('Feature Importance Score')
    plt.title('Top 15 Most Important Features', fontsize=16)
    plt.gca().invert_yaxis()
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ù‚Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ Ø¨Ù‡ Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§
    for i, (bar, importance) in enumerate(zip(bars, top_features['Importance'])):
        plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2, 
                f'{importance:.3f}', va='center')
    
    plt.tight_layout()
    plt.show()
    
    # Ù†Ù…Ø§ÛŒØ´ Ø¬Ø¯ÙˆÙ„ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    print("\nğŸ† Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…:")
    print("=" * 50)
    for idx, row in top_features.iterrows():
        print(f"{row['Feature']:30} â†’ {row['Importance']:.4f}")
    
    return feature_importance_df

# 7. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§
def compare_with_other_models():
    """
    Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§ (Ù…Ø·Ø§Ø¨Ù‚ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ù„Ù‡)
    """
    comparison_data = {
        'Reference': ['[38]', '[39]', '[40]', '[40]', '[41]', '[42]', '[42]', 'Proposed'],
        'Algorithm': ['SVM', 'RF, K-stars, NN', 'Logistic Regression', 'Naive Bayes', 
                     'Decision Tree', 'XGBoost', 'Random Forest', 'XGBoost (Our)'],
        'Accuracy': [83.3, 61.85, 94.4, 92.3, 94.4, 74, 75, 94.74],
        'Samples': [256, 244, 569, 569, 569, 275, 275, 569],
        'Features': [5, 139, 32, 32, 32, 12, 12, 32]
    }
    
    df_comparison = pd.DataFrame(comparison_data)
    
    # Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡
    plt.figure(figsize=(14, 8))
    colors = plt.cm.Set3(np.linspace(0, 1, len(df_comparison)))
    
    bars = plt.bar(range(len(df_comparison)), df_comparison['Accuracy'], color=colors)
    plt.xticks(range(len(df_comparison)), df_comparison['Algorithm'], rotation=45, ha='right')
    plt.ylabel('Accuracy (%)')
    plt.title('Comparison of Different Algorithms (Accuracy)', fontsize=16)
    plt.ylim([0, 100])
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ù‡ Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§
    for bar, acc in zip(bars, df_comparison['Accuracy']):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                f'{acc}%', ha='center', fontsize=10)
    
    # Ù‡Ø§ÛŒÙ„Ø§ÛŒØª Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
    bars[-1].set_edgecolor('red')
    bars[-1].set_linewidth(3)
    
    plt.tight_layout()
    plt.show()
    
    return df_comparison

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
def main():
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
    """
    print("=" * 60)
    print("ğŸ§¬ Breast Cancer Classification using XGBoost")
    print("ğŸ“„ Based on: Rahmanul Hoque et al. (2024)")
    print("=" * 60)
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    X, y = load_data()
    if X is None or y is None:
        return
    
    # 2. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
    X_train, X_test, y_train, y_test = preprocess_data(X, y)
    
    # 3. ØªØ¬Ø³Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    print("\nğŸ“Š Ø¯Ø± Ø­Ø§Ù„ ØªØ¬Ø³Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    visualize_data(X, y)
    
    # 4. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ XGBoost
    model, y_pred, y_pred_proba = train_xgboost(X_train, X_test, y_train, y_test)
    
    # 5. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
    results = evaluate_model(y_test, y_pred, y_pred_proba)
    
    # 6. Ù†Ù…Ø§ÛŒØ´ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    feature_importance_df = plot_feature_importance(model, X.columns.tolist())
    
    # 7. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§
    print("\nğŸ“ˆ Ø¯Ø± Ø­Ø§Ù„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø³Ø§ÛŒØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§...")
    comparison_df = compare_with_other_models()
    
    print("\n" + "=" * 60)
    print("âœ… Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!")
    print("ğŸ¯ Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ:")
    print(f"   Ø¯Ù‚Øª Ù…Ø¯Ù„ XGBoost: {results['accuracy']*100:.2f}%")
    print(f"   Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ: {results['recall']*100:.2f}%")
    print(f"   ØµØ­Øª: {results['precision']*100:.2f}%")
    print("=" * 60)
    
    return {
        'model': model,
        'results': results,
        'feature_importance': feature_importance_df,
        'comparison': comparison_df
    }

# Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
if __name__ == "__main__":
    # Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
    try:
        import xgboost
        import seaborn
        import matplotlib
    except ImportError as e:
        print(f"ğŸ“¦ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: {e}")
        print("Ù„Ø·ÙØ§Ù‹ Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:")
        print("pip install xgboost seaborn matplotlib scikit-learn ucimlrepo")
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ
    main()